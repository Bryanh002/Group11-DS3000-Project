{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf85521-67d2-4348-a8ed-53209709af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve, accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input \n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import keras\n",
    "\n",
    "import time\n",
    "\n",
    "#add other imports here if any (for example, pytorch)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "Label_encoder = LabelEncoder()\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('fraudTrain.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Convert Gender\n",
    "gender_conversion = {'F': 0, 'M': 1}\n",
    "train_data['gender'] = train_data['gender'].map(gender_conversion)\n",
    "\n",
    "train_data['name'] = train_data['first'] + \" \" + train_data['last']\n",
    "train_data['address'] = train_data['street'] + \", \" + train_data['city'] + \", \" + train_data['state']\n",
    "\n",
    "#Convert first name\n",
    "train_data['name'] = Label_encoder.fit_transform(train_data['name'])\n",
    "\n",
    "train_data['age'] = 2024 - pd.to_numeric(train_data['dob'].str[:4]) \n",
    "\n",
    "#Convert Job\n",
    "train_data['job'] = Label_encoder.fit_transform(train_data['job'])\n",
    "\n",
    "train_data['merchant'] = Label_encoder.fit_transform(train_data['merchant'])\n",
    "\n",
    "train_data['category'] = Label_encoder.fit_transform(train_data['category'])\n",
    "\n",
    "train_data['address'] = Label_encoder.fit_transform(train_data['address'])\n",
    "\n",
    "train_data['trans_num'] = Label_encoder.fit_transform(train_data['trans_num'])\n",
    "\n",
    "train_data = train_data.drop(columns=['first', 'last', 'street', 'street', 'city', 'state', 'trans_date_trans_time', 'Unnamed: 0', 'dob'])\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('fraudTest.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Convert Gender\n",
    "gender_conversion = {'F': 0, 'M': 1}\n",
    "test_data['gender'] = test_data['gender'].map(gender_conversion)\n",
    "\n",
    "test_data['name'] = test_data['first'] + \" \" + test_data['last']\n",
    "test_data['address'] = test_data['street'] + \", \" + test_data['city'] + \", \" + test_data['state']\n",
    "\n",
    "#Convert first name\n",
    "test_data['name'] = Label_encoder.fit_transform(test_data['name'])\n",
    "\n",
    "test_data['age'] = 2024 - pd.to_numeric(test_data['dob'].str[:4]) \n",
    "\n",
    "#Convert Job\n",
    "test_data['job'] = Label_encoder.fit_transform(test_data['job'])\n",
    "\n",
    "test_data['merchant'] = Label_encoder.fit_transform(test_data['merchant'])\n",
    "\n",
    "test_data['category'] = Label_encoder.fit_transform(test_data['category'])\n",
    "\n",
    "test_data['address'] = Label_encoder.fit_transform(test_data['address'])\n",
    "\n",
    "test_data['trans_num'] = Label_encoder.fit_transform(test_data['trans_num'])\n",
    "\n",
    "test_data = test_data.drop(columns=['first', 'last', 'street', 'street', 'city', 'state', 'trans_date_trans_time', 'Unnamed: 0', 'dob'])\n",
    "\n",
    "\n",
    "train_data.head()\n",
    "y_train = train_data[\"is_fraud\"]\n",
    "x_train = train_data.drop(columns=[\"is_fraud\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1a6a8-3034-47b3-968a-67bc1417c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()\n",
    "y_test = test_data[\"is_fraud\"]\n",
    "x_test = test_data.drop(columns=[\"is_fraud\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2660286-e805-4ba8-94ce-ebc49641231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567469a-492e-48fd-962c-1724e37b00f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sc = StandardScaler() \n",
    "x_train_std = sc.fit_transform(x_train)\n",
    "x_test_std = sc.transform(x_test)\n",
    "\n",
    "#Use SMOTE (Synthetic Minority Oversampling Technique) to generate more samples of the fraud class.\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f317e8-c036-4ebb-8901-852886b52555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "def Grid_Search_NN_model(hidden_neurons=8, learning_rate=0.1, dropout_rate=0.5):\n",
    "    input_layer = Input(shape=(x_train_std.shape[1],))\n",
    "    hidden1 = Dense(hidden_neurons)(input_layer)\n",
    "    hidden1 = ReLU(alpha=0.01)(hidden1)\n",
    "    hidden1 = Dropout(dropout_rate)(hidden1) \n",
    "    \n",
    "    hidden2 = Dense(hidden_neurons)(hidden1)\n",
    "    hidden2 = ReLU(alpha=0.01)(hidden2)\n",
    "    hidden2 = Dropout(dropout_rate)(hidden2)\n",
    "\n",
    "    hidden3 = Dense(hidden_neurons)(hidden2)\n",
    "    hidden3 = ReLU(alpha=0.01)(hidden3)\n",
    "    hidden3 = Dropout(dropout_rate)(hidden3)\n",
    "\n",
    "    hidden4 = Dense(hidden_neurons)(hidden3)\n",
    "    hidden4 = ReLU(alpha=0.01)(hidden4)\n",
    "    hidden4 = Dropout(dropout_rate)(hidden4)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(hidden2)\n",
    "\n",
    "    \n",
    "    # Create the model object\n",
    "    myGSModel = Model(inputs=input_layer, outputs=output)  \n",
    "\n",
    "    # Define optimizer with learning rate\n",
    "    optimizer =  keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    myGSModel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return myGSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5efee-784b-4b6f-a31b-54fb999bf388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gridsearch here\n",
    "param_grid = {\n",
    "    \"model__hidden_neurons\": [8, 16, 32],  # Number of neurons in each hidden layer\n",
    "    \"model__learning_rate\": [0.01, 0.1],  # Learning rates to test\n",
    "    \"batch_size\": [32],                   # Fixed batch size\n",
    "    \"epochs\": [20]                        # Number of epochs per training session\n",
    "}\n",
    "\n",
    "\n",
    "#to use a keras model with sklearn we need to call a wrapper function where the build function is our previously defined function\n",
    "model = KerasClassifier(model=Grid_Search_NN_model, verbose=0)\n",
    "#instantiate gridsearch object using 3 fold crossvaliadtion\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "#fit the gridsearch object on the data\n",
    "grid_result = grid.fit(x_train_std, y_train)\n",
    "#determine the best parameter\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bd674-a8dd-48d5-9976-a40960700929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Best Hyperparameters: {grid_result.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_result.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f582bad-5735-4102-88be-82e4f928c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASED OFF OF AWESOME GRID SEARCH RESULTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd7ef7-af0a-4dd1-965f-2e934271ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED TO EDIT THIS BASED OFF HYPER PARAMETER OPTIMIZATION\n",
    "#NEED TO EDIT THIS BASED OFF HYPER PARAMETER OPTIMIZATION\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "losses = []\n",
    "\n",
    "param_grid2 = {\n",
    "    \"model_hidden_neurons\": [16],\n",
    "    \"model_learning_rate\": [0.1],\n",
    "    \"batch_size\": [32],\n",
    "    \"epochs\": [20]\n",
    "}\n",
    "\n",
    "model2 = Grid_Search_NN_model(hidden_neurons=16, learning_rate = 0.1, dropout_rate = 0.5)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "best_model = model2.fit(\n",
    "    x_train_resampled,\n",
    "    y_train_resampled,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose = 1,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f60c0-a0ec-4b55-bfa3-9a842d06e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = best_model.history['loss']\n",
    "\n",
    "y_pred = model2.predict(x_test_std)\n",
    "y_pred_val = (y_pred >= 0.5)\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, y_pred_val)\n",
    "recall = recall_score(y_test, y_pred_val)\n",
    "f1 = f1_score(y_test, y_pred_val)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(losses) + 1), losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Loss vs. Epochs', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Binary Cross-Entropy Loss', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#1 hidden layers\n",
    "#Precision: 0.6412\n",
    "#Recall: 0.5748\n",
    "#F1-Score: 0.6062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a08d09-dd12-486f-9214-793d3e3ca839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
