{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bf85521-67d2-4348-a8ed-53209709af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve, accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input \n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import keras\n",
    "\n",
    "import time\n",
    "\n",
    "#add other imports here if any (for example, pytorch)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "Label_encoder = LabelEncoder()\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('fraudTrain.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Convert Gender\n",
    "gender_conversion = {'F': 0, 'M': 1}\n",
    "train_data['gender'] = train_data['gender'].map(gender_conversion)\n",
    "\n",
    "train_data['name'] = train_data['first'] + \" \" + train_data['last']\n",
    "train_data['address'] = train_data['street'] + \", \" + train_data['city'] + \", \" + train_data['state']\n",
    "\n",
    "#Convert first name\n",
    "train_data['name'] = Label_encoder.fit_transform(train_data['name'])\n",
    "\n",
    "train_data['age'] = 2024 - pd.to_numeric(train_data['dob'].str[:4]) \n",
    "\n",
    "#Convert Job\n",
    "train_data['job'] = Label_encoder.fit_transform(train_data['job'])\n",
    "\n",
    "train_data['merchant'] = Label_encoder.fit_transform(train_data['merchant'])\n",
    "\n",
    "train_data['category'] = Label_encoder.fit_transform(train_data['category'])\n",
    "\n",
    "train_data['address'] = Label_encoder.fit_transform(train_data['address'])\n",
    "\n",
    "train_data['trans_num'] = Label_encoder.fit_transform(train_data['trans_num'])\n",
    "\n",
    "train_data = train_data.drop(columns=['first', 'last', 'street', 'street', 'city', 'state', 'trans_date_trans_time', 'Unnamed: 0', 'dob'])\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('fraudTest.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Convert Gender\n",
    "gender_conversion = {'F': 0, 'M': 1}\n",
    "test_data['gender'] = test_data['gender'].map(gender_conversion)\n",
    "\n",
    "test_data['name'] = test_data['first'] + \" \" + test_data['last']\n",
    "test_data['address'] = test_data['street'] + \", \" + test_data['city'] + \", \" + test_data['state']\n",
    "\n",
    "#Convert first name\n",
    "test_data['name'] = Label_encoder.fit_transform(test_data['name'])\n",
    "\n",
    "test_data['age'] = 2024 - pd.to_numeric(test_data['dob'].str[:4]) \n",
    "\n",
    "#Convert Job\n",
    "test_data['job'] = Label_encoder.fit_transform(test_data['job'])\n",
    "\n",
    "test_data['merchant'] = Label_encoder.fit_transform(test_data['merchant'])\n",
    "\n",
    "test_data['category'] = Label_encoder.fit_transform(test_data['category'])\n",
    "\n",
    "test_data['address'] = Label_encoder.fit_transform(test_data['address'])\n",
    "\n",
    "test_data['trans_num'] = Label_encoder.fit_transform(test_data['trans_num'])\n",
    "\n",
    "test_data = test_data.drop(columns=['first', 'last', 'street', 'street', 'city', 'state', 'trans_date_trans_time', 'Unnamed: 0', 'dob'])\n",
    "\n",
    "\n",
    "train_data.head()\n",
    "y_train = train_data[\"is_fraud\"]\n",
    "x_train = train_data.drop(columns=[\"is_fraud\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c1a6a8-3034-47b3-968a-67bc1417c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()\n",
    "y_test = test_data[\"is_fraud\"]\n",
    "x_test = test_data.drop(columns=[\"is_fraud\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a567469a-492e-48fd-962c-1724e37b00f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler() \n",
    "x_train_std = sc.fit_transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71f317e8-c036-4ebb-8901-852886b52555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grid_Search_NN_model(hidden_neurons=8, learning_rate=0.1):\n",
    "    # Define the input layer\n",
    "    input_layer = Input(shape=(x_train_std.shape[1],))  # Input shape is based on your training data shape\n",
    "    # Define the first hidden layer and the previously connected layer\n",
    "    hidden1 = Dense(hidden_neurons)(input_layer)\n",
    "    hidden1 = LeakyReLU(alpha=0.01)(hidden1)# LEAKY RELU!!! super awesome activation function\n",
    "    # Define the output layer and the previously connected layer\n",
    "    output = Dense(1, activation='sigmoid')(hidden1)\n",
    "    \n",
    "    # Create the model object\n",
    "    myGSModel = Model(inputs=input_layer, outputs=output)  # Use `inputs` and `outputs` arguments\n",
    "\n",
    "    # Define optimizer with learning rate\n",
    "    optimizer =  keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    myGSModel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return myGSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5efee-784b-4b6f-a31b-54fb999bf388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "# Run gridsearch here\n",
    "param_grid = {\n",
    "    \"model__hidden_neurons\": [8, 16, 32],  # Number of neurons in each hidden layer\n",
    "    \"model__learning_rate\": [0.01, 0.1],  # Learning rates to test\n",
    "    \"batch_size\": [32],                   # Fixed batch size\n",
    "    \"epochs\": [20]                        # Number of epochs per training session\n",
    "}\n",
    "\n",
    "\n",
    "#to use a keras model with sklearn we need to call a wrapper function where the build function is our previously defined function\n",
    "model = KerasClassifier(model=Grid_Search_NN_model, verbose=0)\n",
    "#instantiate gridsearch object using 3 fold crossvaliadtion\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "#fit the gridsearch object on the data\n",
    "grid_result = grid.fit(x_train_std, y_train)\n",
    "#determine the best parameter\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bd674-a8dd-48d5-9976-a40960700929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Best Hyperparameters: {grid_result.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_result.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f582bad-5735-4102-88be-82e4f928c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASED OFF OF AWESOME GRID SEARCH RESULTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd7ef7-af0a-4dd1-965f-2e934271ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED TO EDIT THIS BASED OFF HYPER PARAMETER OPTIMIZATION\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(X_train_std.shape[1],), activation = 'tanh'))\n",
    "model.compile(optimizer = keras.optimizers.SGD(learning_rate=0.1), loss='BinaryCrossentropy', metrics=['accuracy', 'precision'])\n",
    "print(model.summary())\n",
    "\n",
    "#maybe add cross validation\n",
    "history = model.fit(X_train_std, y_train, epochs = 10, verbose=0, batch_size = 32)\n",
    "losses2 = history.history['loss']\n",
    "#idk\n",
    "y_pred = model.predict(X_test_std)\n",
    "y_pred_val = (y_pred >= 0.5)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(losses2) + 1), losses2, marker='o', linestyle='-', color='b')\n",
    "plt.title('Loss vs. Epochs', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Binary Cross-Entropy Loss', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
